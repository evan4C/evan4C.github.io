---
title: AI经典文献和资料
date: 2023-6-1
categories: [AI]
tags: [legacy]
---

[AI Canon | Andreessen Horowitz](https://a16z.com/2023/05/25/ai-canon/)

# <font style="color:rgb(42, 42, 42);">基础介绍</font>

## [软件 2.0](https://karpathy.medium.com/software-2-0-a64152b37c35)<font style="color:rgb(42, 42, 42);"></font>

<font style="color:rgb(42, 42, 42);">Andrej Karpathy, 2017</font>

<font style="color:rgb(42, 42, 42);">神经网络不只是分类器，还代表着向新一代编程方式：软件 2.0 的转变。</font>

<font style="color:rgb(42, 42, 42);">软件 1.0 的代表是各种编程语言，程序员通过每行代码来定义程序。而软件 2.0 中程序则是由神经网络的权重来定义，更抽象也对人类的理解更不友好。在这种情形下，程序员的目标不再是编写清晰的代码，而是定义程序的目标（分类或预测），然后设计代码框架（神经网络架构）来约束搜索程序的空间大小，最后使用硬件资源在指定的搜索空间内找到符合需要的程序（合适的权重）。</font>

![](https://cdn.nlark.com/yuque/0/2023/png/35875115/1685454728470-98e3c370-1e27-48f8-9588-db2a464e8b9b.png)

在软件 1.0 中，人工编写的源代码（例如一些.cpp 文件）被编译成可以执行有用工作的二进制代码。

在软件 2.0 中，源代码通常包括两部分：1）定义 desirable 行为的数据集，2）需要填充具体细节（权重）的神经网络架构。训练神经网络的过程相当于将数据集编译成最终神经网络的二进制代码。

在当今大多数实际应用中，神经网络架构和训练系统越来越标准化并且成为人人可用的商品化产品，因此<font style="background-color:#FBDE28;">大部分活跃的"软件开发"转变为对标记数据集的筛选、扩充、处理和清洗。</font>这从根本上改变了我们迭代软件的编程范式，因为软件工程师们将分成两个部分：2.0 程序员（数据标注人员）负责编辑和扩充数据集；一小部分 1.0 程序员则维护和迭代训练代码的基础设施、分析、可视化和标注接口。

对于解决物理世界中的大多数问题而言，收集数据（定义 desirable 行为）往往比编写复杂的程序更为有效和简单，因此软件 2.0 在未来必然会慢慢取代软件 1.0，而这种转变实际上已经在图像分类、语音合成、机器翻译、游戏等领域发生。

软件 2.0（以卷积神经网络为例）相比于软件 1.0（以 C++量产代码库为例）的优势：

1. **计算同质性。**神经网络的计算过程相对简单，主要由矩阵乘法和阈值处理（ReLU）组成，这使得我们能够更容易地评估其正确性和性能。与之相比，软件 1.0 的代码库更加复杂和异质化，对其正确性和性能进行保证会变得更加困难。
2. **硬件优化更容易。**由于神经网络的指令集相对较小，因此更容易将这些网络的实现和芯片设计相结合，例如使用定制的 ASIC 芯片、神经形态芯片等等。
3. **恒定的运行时间。**神经网络的每个迭代都具有相同的计算复杂度，这意味着无论输入的数据如何，执行时间都是固定的。与传统的计算机程序相比，神经网络的执行时间更加可预测和稳定。这样的特性使得我们更容易对神经网络的性能进行分析和优化，并避免出现意外的计算问题，如无限循环。
4. **恒定的内存使用量。**由于神经网络没有动态分配内存的需求，内存使用量是固定的。这意味着我们不需要担心内存泄漏或内存溢出等问题，也不需要花费时间来定位和修复这些问题，使得神经网络的开发和部署更加简化和可靠。
5. **高度的可移植性。**由于神经网络主要由矩阵乘法操作组成，不依赖于特定的操作系统或编程语言。这使得神经网络具有很强的可移植性，可以在不同的硬件设备上运行，为神经网络的部署和应用带来了很大的便利。
6. **灵活性。**如果你有一段 C++代码，将其运行速度提高一倍是非常困难的。然而，在软件 2.0 中，我们可以取出神经网络的一半通道，重新训练，这样就可以以正好两倍的速度运行。通过调整网络结构并重新训练网络，我们可以在不同的需求和资源条件下快速调整网络的性能和效果。这种灵活性使得我们能够更加敏捷地优化和改进我们的程序，而无需进行复杂的系统调整。
7. **可融合性。**传统软件通常被分解为通过公共函数或 API 进行通信的模块。在软件 2.0 中，不同模块之间的交互和融合变得更加容易。如果两个最初分别进行训练的软件 2.0 模块进行交互，我们可以轻松地通过整个系统进行反向传播。
8. **比人类更优秀。**在许多有价值的领域中，特别是在与图像/视频、声音/语音相关的领域，神经网络是一种比你我能够创建的任何代码都更出色的解决方案。它们能够通过大规模的数据训练和学习来自动捕捉复杂的模式和特征，从而在视觉和音频任务上取得出色的性能。

软件 2.0 存在的问题和局限性：

1. 黑盒。大模型的可解释性比较差，在优化的最后阶段，我们得到了效果良好的大型神经网络，但还是很难了解其内部运作方式。
2. 默默失败。由于大型神经网络的复杂性和高度自适应性，它们有可能在不为人察觉的情况下采用训练数据中的偏见。这可能导致系统对某些特定类别或属性的偏好或歧视性行为。
3. 敏感性。敌对攻击是指通过对输入数据进行微小的、人类难以察觉的修改，或使用有意制造的敌对样本，可以使神经网络产生误判或错误的输出。由于神经网络在训练过程中学习到的复杂模式和特征，有时候它们可能对微小的扰动非常敏感，导致错误的预测或分类。

在编写软件 1.0 代码方面，我们已经建立了大量的工具以帮助人们进行开发，例如功能强大的集成开发环境（IDE），具有语法高亮、调试器、性能分析工具、跳转到定义、与 Git 集成等功能。在软件 2.0 中，编程是通过积累、整理和清理数据集来完成的。例如，当网络在某些复杂或罕见的情况下失败时，我们不是通过编写代码来修复这些预测，而是通过增加更多有标签的样例来改进模型对这些情况的预测能力。那么谁会开发第一个用于辅助 2.0 编程工作流程的集成开发环境（IDE）呢？这样的 IDE 将帮助我们在积累、可视化、清理、标注和获取数据集方面进行工作。也许这个 IDE 可以基于每个样例的损失情况，提供可能被网络误标的图像；或者通过预测结果为标签提供初始值，辅助标注过程；又或者根据网络预测的不确定性，建议有用的样例进行标注。

类似地，Github 是一个非常成功的软件 1.0 代码的托管平台。是否存在一个适用于软件 2.0 的类似 Github 的平台呢？在这种情况下，代码库可以看作是数据集，提交则由对标签的添加和编辑组成。

## [GPT 现状](https://build.microsoft.com/en-US/sessions/db3f4859-cd30-4445-a0cd-553c3304f8e2)<font style="color:rgb(42, 42, 42);"></font>

Andrej Karpathy (Microsoft Build 2023)

![](https://cdn.nlark.com/yuque/0/2023/png/35875115/1685603352451-97d62647-c51c-4f91-9676-8e18e3a263d7.png)

**Data Collection：**从互联网的公开数据源收集大量训练数据，如下所示为 LLaMA 的预训练数据集

![](https://cdn.nlark.com/yuque/0/2023/png/35875115/1685603645434-e11f35f2-d07a-476f-a23b-8ecb6cc81434.png)

**Tokenization：**把文本转换为数字序列

![](https://cdn.nlark.com/yuque/0/2023/png/35875115/1685603843572-42d317a9-c9c0-45ca-bfe6-d15c6fecde89.png)

## [ChatGPT 在做什么，以及为什么它有效？](https://writings.stephenwolfram.com/2023/02/what-is-chatgpt-doing-and-why-does-it-work/)

<font style="color:rgb(42, 42, 42);">By Stephen Wolfram@Wolfram</font>

<font style="color:rgb(42, 42, 42);">LLM 的目标是预测下一个单词和它的概率。</font>

![](https://cdn.nlark.com/yuque/0/2023/png/35875115/1687094966075-1b9b8d9f-67aa-41a0-8c1d-b13c33189f9e.png)

[GPT2 Transformer - Wolfram Neural Net Repository](https://resources.wolframcloud.com/NeuralNetRepository/resources/GPT2-Transformer-Trained-on-WebText-Data/)

## [模型演变解释](https://daleonai.com/transformers-explained)

<font style="color:rgb(42, 42, 42);">By Dale Markowitz@Google Research</font>

RNN 有以下两个致命缺点，因此被 Transform 取代：

1. 难以训练，容易出现梯度消失等问题。
2. 因为采用序列化处理文本的方式，很难通过并行计算来进行加速。

一句话解释 Transromer：

> Combine a model that scales well with a huge dataset and the results will likely blow you away.

## [Stable Diffusion 的工作原理](https://mccormickml.com/2022/12/21/how-stable-diffusion-works/)

<font style="color:rgb(42, 42, 42);">Chris McCormick</font>

<font style="color:rgb(42, 42, 42);">Stable Diffusion 是一个用来移除图片噪音的深度神经网络。</font>

最开始 Stable Diffusion 会收到一幅完全由噪音组成的图片，然后我们通过输入提示语（Prompt）指示 Stable Diffusion 这其实是一幅关于骷髅弹吉他的画，Tokenization 之后的提示语和原始图片作为输入神经网络的输入，使用提前训练好的 10 亿参数，Stable Diffusion 便可以生成用户需要的图像。

# **<font style="color:rgb(42, 42, 42);">基础学习：神经网络、反向传播和嵌入</font>**

## [深度学习简介：核心概念](https://developer.nvidia.com/blog/deep-learning-nutshell-core-concepts/)

<font style="color:rgb(42, 42, 42);">Nvidia，2015</font>

1. <font style="color:rgb(42, 42, 42);">深度学习 3 步法：收集数据，根据收集到的数据训练模型，使用训练好的模型在新的数据上进行预测。</font>
2. <font style="color:rgb(42, 42, 42);">特征工程（Feature Engineering）：从数据中</font>**<font style="color:rgb(42, 42, 42);">人工提取</font>**<font style="color:rgb(42, 42, 42);">出有用的模式（Pattern）从而使机器学习模型可以更好地对数据进行分类。例如，图像中蓝色或黄色像素的数量可以用来区分图像是水生或陆地动物。</font>
3. <font style="color:rgb(42, 42, 42);">特征学习（Feature Learning）：通过算法</font>**<font style="color:rgb(42, 42, 42);">自动</font>**<font style="color:rgb(42, 42, 42);">找到有用的模式（Pattern）并用于数据的分类或回归。例如，在深度学习中，卷积层非常擅长在下一层的图像中找到有用的模式，并形成越来越复杂的非线性特征，最后使用这些复杂的特征进行分类（斑点、边缘>>鼻子、眼睛>>面孔>>人脸识别）。</font>
4. <font style="color:rgb(42, 42, 42);">深度学习：上面提到的分层特征学习模型架构存在梯度消失等问题，因此和浅层学习（SVM）相比性能很差。而深度学习的目标正是通过克服梯度消失等问题来生成具有深层（数十层）非线性层次结构的模型。</font>
5. <font style="color:rgb(42, 42, 42);">逻辑回归（Logistic Regression）：使用 sigmoid 函数预测某种结果出现的可能性。在深度学习中，分类神经网络的最后一层通常是逻辑回归。</font>
6. <font style="color:rgb(42, 42, 42);">卷积（Convolution）：描述如何混合两个输入量的一种数学运算，也被解释为特征的过滤器（Filter）。输入数据（Input data）和卷积内核（Convolution kernel）通过矩阵乘法，生成转换后的特征图（Feature map）</font>

![](https://cdn.nlark.com/yuque/0/2023/png/35875115/1687320574131-9a074807-9813-4111-b16b-843ad9134d1d.png)

7. <font style="color:rgb(42, 42, 42);">池化/子采样（Pooling/Subsampling）：将一个特定区域的输入量简化为单个值的过程，在 CNN 中用于集中或浓缩最有用的信息，作用类似于漏斗，具备旋转和平移不变性，减少了 CNN 的内存消耗，因此可以使用更多的卷积层，但是池化区过大会丢失太多信息导致预测性能下降。</font>
8. <font style="color:rgb(42, 42, 42);">随机梯度下降（SGD）：</font>
9. <font style="color:rgb(42, 42, 42);">丢失（Dropout）：Dropout 可以对不同神经元的信息处理进行解耦，使每个神经元能够独立于权重大的神经元的影响，通过确保更少的极端意见来减少偏见，降低模型的过拟合。</font>
10. <font style="color:rgb(42, 42, 42);">正则化（Regularization）：通过限制参数的大小限制了神经网络中权重的大小，因此高置信度的输出值无法从单个大权重中实现，而是需要几个中等大小的权重，从而减少了泛化误差。</font>
11. <font style="color:rgb(42, 42, 42);">单词嵌入（Word embedding）：将单词转换成一个表示该单词的数值向量。想象我们把“cat”放到一个 3 维空间中，其坐标为（0, 0, 0），那么和“cat”类似的词（tiger, lion 等）比起不相似的词（car, house 等）在这个控件中将更靠近“cat”的位置。即 tiger 的坐标可能是（1, 2, 3），而汽车可能是（10, -5, 20）。这些坐标代表单词的嵌入向量，实际使用的单词嵌入空间通常包括数百个维度，即向量长度大于 100。</font>
12. <font style="color:rgb(42, 42, 42);">编码器-解码器（Encoder-Decoder）：最初用在机器翻译中，基本思想是两种不同语言的表示在单词嵌入空间中具有相似的几何关系。例如猫和狗在德语和英语中的单词完全不一样，但是单词之间的潜在关系几乎是相同的。因此我们可以使用编码器把英语中的句子生成英语单词嵌入空间中的“thought vertors”然后在德语单词嵌入空间中再通过解码器将其转换成对应的句子。</font>
13. <font style="color:rgb(42, 42, 42);">强化学习（Reinforcement learning）：讨论一个智能体（agent）怎么在一个复杂且不确定的环境（environment）里面去最大化它能获得的奖励。通过感知所处环境的状态（state）对动作（action）的反应（reward），来指导更好的动作，从而获得最大的收益（return），也被称为在交互中学习。</font>

## [实用深度学习教程](https://course.fast.ai/)

<font style="color:rgb(42, 42, 42);">Jeremy Howard，课程笔记参考下面文档</font>

[Practical Deep Learning for Coders](https://www.yuque.com/evan4k/ux3oqi/qr7krqvu34ymwuvw)

## [Word2Vec 解释](https://medium.com/m/global-identity-2?redirectUrl=https%3A%2F%2Ftowardsdatascience.com%2Fword2vec-explained-49c52b4ccb71)

Vatsal, 2021

<font style="color:rgb(42, 42, 42);">Word2Vec 是一种 word embedding 技术，可以高效地将相似单词的向量进行分组。</font>

## [是的，你应该了解反向传播](https://karpathy.medium.com/yes-you-should-understand-backprop-e2f06eab496b)

<font style="color:rgb(42, 42, 42);">如果你想要了解更多细节，可以阅读更深入的关于反向传播的文章。如果您还想进一步了解，可以尝试在 YouTube 上观看</font>[斯坦福大学的 CS231n 课程讲座](https://www.youtube.com/watch?v=i94OvYb6noo)**<font style="color:rgb(42, 42, 42);">。</font>**

## [斯坦福大学 CS229](https://www.youtube.com/playlist?list=PLoROMvodv4rMiGQp3WXShtMGgzqpfVfbU)

<font style="color:rgb(42, 42, 42);">由 Andrew Ng 主讲的机器学习入门课程，涵盖机器学习的基础知识。</font>

## [斯坦福大学 CS224N](https://www.youtube.com/playlist?list=PLoROMvodv4rOSH4v6133s9LFPRHjEmbmJ)

<font style="color:rgb(42, 42, 42);">由 Chris Manning 主讲的深度学习自然语言处理（NLP）课程，涵盖了从 NLP 基础知识到第一代大型语言模型（LLMs）的内容。</font>

# **<font style="color:rgb(42, 42, 42);">技术深入探究：理解 Transformer 和大型语言模型</font>**

## [The Illustrated Transformer](https://jalammar.github.io/illustrated-transformer/)

<font style="color:rgb(42, 42, 42);">由 Jay Alammar 提供的对 Transformer 架构更为技术性的概述。</font>

## [The Annotated Transformer](http://nlp.seas.harvard.edu/annotated-transformer/)**<font style="color:rgb(42, 42, 42);"></font>**

<font style="color:rgb(42, 42, 42);">这是一篇深入的文章，如果您想基于会编写源代码的水平理解 Transformer，这篇文章会帮助您。需要一些 PyTorch 的知识基础。</font>

## [让我们构建 GPT](https://www.youtube.com/watch?v=kCc8FmEb1nY)

<font style="color:rgb(42, 42, 42);">从头开始，在代码中一步步实现：针对工程师们，Karpathy 进行了视频演示，展示了如何构建 GPT 模型。</font>

## [The Illustrated Stable Diffusion](https://jalammar.github.io/illustrated-stable-diffusion/)

<font style="color:rgb(42, 42, 42);">对潜在扩散模型（Stable Diffusion）的介绍，这是最常见的用于图像生成的生成式人工智能模型类型。</font>

## [RLHF](https://huyenchip.com/2023/05/02/rlhf.html)

<font style="color:rgb(42, 42, 42);">从人类反馈中进行强化学习：Chip Huyen 解释了 RLHF，它可以使 LLMs 以更可预测和人性化的方式运行。这是 ChatGPT 等系统中最重要但理解最少的方面之一。</font>

## [从人类反馈中进行强化学习](https://www.youtube.com/watch?v=hhiLw5Q_UFg)

<font style="color:rgb(42, 42, 42);">计算机科学家和 OpenAI 联合创始人 John Shulman 在这个出色的演讲中深入探讨了 LLMs 与 RLHF 的当前状态、进展和局限性。</font>

## [Stanford CS25: Transformers United](https://www.youtube.com/watch?v=P127jhj-8-Y)

<font style="color:rgb(42, 42, 42);">这是关于 Transformer 的在线研讨会，由斯坦福大学主办。</font>

## [Stanford CS324: Large Language Models](https://stanford-cs324.github.io/winter2022/)

<font style="color:rgb(42, 42, 42);">由 Percy Liang、Tatsu Hashimoto 和 Chris Re 主讲，涵盖大型语言模型的广泛技术和非技术方面的课程。</font>

## [预测性学习, NIPS 2016](https://www.youtube.com/watch?v=Ount2Y4qxQo&t=1072s)

<font style="color:rgb(42, 42, 42);">在这个早期的演讲中，Yann LeCun 为无监督学习作为大规模 AI 模型架构中的关键要素提出了有力的论点。在 19:20 处跳到著名的蛋糕类比部分，这仍然是对现代 AI 最好的模型之一。</font>

## [人工智能技术应用于特斯拉自动驾驶](https://www.youtube.com/watch?v=hx7BXih7zx8)

<font style="color:rgb(42, 42, 42);">另一个经典的 Karpathy 演讲，这次涵盖了特斯拉数据收集引擎。从 8:35 开始是一个有关为什么长尾问题（在本例中是停止标志检测）如此困难的人工智能讲述。</font>

## [标度假设](https://gwern.net/scaling-hypothesis)

<font style="color:rgb(42, 42, 42);">大语言模型最令人惊讶的一个方面是，扩大规模——增加更多的数据和计算资源——会不断提高准确性。GPT-3 是第一个清楚证明这一点的模型，Gwern 的文章很好地解释了其背后的直觉。</font>

## [Chinchilla’s wild implications](https://www.lesswrong.com/posts/6Fpvch8RR29qLEWNH/chinchilla-s-wild-implications)

<font style="color:rgb(42, 42, 42);">这篇文章被称为对重要的 Chinchilla 论文的解释（请参见下文），它深入探讨了 LLM 扩展中的一个重要问题：我们是否正在耗尽数据资源？这篇文章在上面的文章基础上进行了扩展，并对扩展规律提供了新的观点。</font>

## [关于大语言模型的总体研究](https://arxiv.org/pdf/2303.18223v4.pdf)

<font style="color:rgb(42, 42, 42);">全面介绍了当前大型语言模型，包括发展时间线、模型规模、训练策略、训练数据、硬件等等。</font>

## [Sparks of AGI: GPT-4 的早期实验](https://arxiv.org/abs/2303.12712)

<font style="color:rgb(42, 42, 42);">微软研究团队对 GPT-4 的能力进行了早期分析，GPT-4 是目前最先进的 LLM，相对于人类智能进行了对比。</font>

[人工智能的革命: How Auto-GPT unleashes a new era of automation and creativity](https://pub.towardsai.net/the-ai-revolution-how-auto-gpt-unleashes-a-new-era-of-automation-and-creativity-2008aa2ca6ae)

<font style="color:rgb(42, 42, 42);">介绍 Auto-GPT 和 AI 代理的一篇文章。这项技术还处于早期阶段，但理解它非常重要，它利用互联网访问和自我生成的子任务来解决特定复杂问题或目标。</font>

[Waluigi 效应](https://www.lesswrong.com/posts/D7PumeYTDPfBTp3i7/the-waluigi-effect-mega-post)

<font style="color:rgb(42, 42, 42);">名义上是对“Waluigi 效应”（即为什么 LLM 行为中出现“替代自我”）的解释，但它主要作用是对 LLM 提示理论的深入剖析。</font>

## **<font style="color:rgb(42, 42, 42);">使用大型语言模型（LLMs）进行构建的实用指南</font>**

## [使用 GPT3、LangChain 和 Python 构建 GitHub 支持机器人](https://dagster.io/blog/chatgpt-langchain)

<font style="color:rgb(42, 42, 42);">这是关于现代 LLM 应用程序堆栈的最早公开解释之一。其中的一些建议可能有些过时，但在许多方面它推动了广泛采用和实验新的 AI 应用程序。</font>

## [构建用于生产的 LLM 应用程序](https://huyenchip.com/2023/04/11/llm-engineering.html)

<font style="color:rgb(42, 42, 42);">Chip Huyen 讨论了构建大语言模型应用程序的许多关键挑战，如何解决这些挑战以及哪些用例是最合适的。</font>

## [Prompt 工程指南](https://www.promptingguide.ai/zh)

<font style="color:rgb(42, 42, 42);">对于任何编写大语言模型提示的人（包括应用程序开发人员），这是最全面的指南，提供了一些热门模型的具体示例。如果您希望轻松、更具对话性的处理方式，请尝试 Brex 的 Prompt 工程指南。</font>

## [Prompt 注入](https://simonwillison.net/2023/Apr/14/worst-that-can-happen/)

<font style="color:rgb(42, 42, 42);">最糟糕的情况是什么？Prompt 注入是一种潜在的严重安全漏洞，潜藏在大语言模型应用程序中，目前还没有完美的解决方案。Simon Willison 在这篇文章中对这个问题进行了权威的描述。Simon 在 AI 方面的所有文章几乎都是出色的。</font>

## [OpenAI Cookbook](https://github.com/openai/openai-cookbook/tree/main)

<font style="color:rgb(42, 42, 42);">对于开发人员来说，这是使用 OpenAI API 进行工作的指南和代码示例的权威集合。它会不断更新以提供新的代码示例。</font>

## [Pinecone 学习中心](https://www.pinecone.io/learn/)

<font style="color:rgb(42, 42, 42);">许多大语言模型应用程序基于向量搜索范式。尽管被品牌厂商包装，Pinecone 的学习中心提供了一些关于如何构建这种模式的最有用的指导。</font>

## [LangChain 文档](https://python.langchain.com/en/latest/index.html)

<font style="color:rgb(42, 42, 42);">作为大语言模型应用程序的默认编排层，LangChain 连接了堆栈中的几乎所有其他部分。因此，他们的文档是整个堆栈以及各个部分如何配合的真正参考。</font>

## [LLM Bootcamp](https://fullstackdeeplearning.com/llm-bootcamp/)<font style="color:rgb(42, 42, 42);"></font>

<font style="color:rgb(42, 42, 42);">由 Charles Frye、Sergey Karayev 和 Josh Tobin 主讲的一个实践课程，用于构建基于大语言模型的应用程序。</font>

## [Hugging Face Transformers](https://huggingface.co/learn/nlp-course/chapter1/1)

<font style="color:rgb(42, 42, 42);">使用 Hugging Face Transformers 库中的开源大语言模型的指南。</font>

## [Chatbot Arena](https://lmsys.org/blog/2023-05-03-arena/)

<font style="color:rgb(42, 42, 42);">由加州大学伯克利分校的团队领导的一种类似 Elo 积分制的热门 LLM 排名系统。用户也可以通过比较模型进行头对头比赛来参与其中。</font>

## [Open LLM Leaderboard](https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard)

<font style="color:rgb(42, 42, 42);">由 Hugging Face 提供的排名，比较开源 LLM 在一系列标准基准和任务上的表现。</font>

# **<font style="color:rgb(42, 42, 42);">市场分析</font>**

<font style="color:rgb(42, 42, 42);">我们都为生成式人工智能所创造的成果感到惊叹，但仍然有许多关于这一切意义的问题。哪些产品和公司将生存和繁荣？艺术家们将会面临什么情况？公司应该如何利用它？它将如何影响就业和整个社会？</font>

## [谁拥有生成式人工智能平台？](https://a16z.com/2023/01/19/who-owns-the-generative-ai-platform/)

<font style="color:rgb(42, 42, 42);">这是我们对生成式人工智能基础设施、模型和应用层的价值积累以及可能积累的核心评估。</font>

## [应对高昂的 AI 计算成本](https://a16z.com/2023/04/27/navigating-the-high-cost-of-ai-compute/)

<font style="color:rgb(42, 42, 42);">详细分析为什么生成式人工智能模型需要如此多的计算资源，以及如何在需求旺盛的市场中获取这些资源（即以正确的成本获得正确数量的图形处理器）。</font>

## [艺术并未消亡，而是由机器生成](https://a16z.com/2022/11/16/creativity-as-an-app/)

<font style="color:rgb(42, 42, 42);">探讨人工智能模型如何比软件开发等领域更快地改变被认为是自动化的最后阵地的创意领域。</font>

## [生成式人工智能在游戏中的革命](https://a16z.com/2022/11/17/the-generative-ai-revolution-in-games/)

<font style="color:rgb(42, 42, 42);">我们游戏团队对如何轻松创建高度详细图形将如何改变游戏设计师、工作室和整个市场的分析。我们游戏团队的这篇后续文章专门讨论了 AI 生成内容与用户生成内容的出现。</font>

## [对于 B2B 生成式人工智能应用](https://a16z.com/2023/03/30/b2b-generative-ai-synthai/)

<font style="color:rgb(42, 42, 42);">对大语言模型在 B2B 企业应用领域如何演变的预测，重点在于总结信息最终比产生文本更有价值。</font>

## [金融服务业将比你想象中更快地接受生成式人工智能](https://a16z.com/2023/04/19/financial-services-will-embrace-generative-ai-faster-than-you-think/)

<font style="color:rgb(42, 42, 42);">论述金融服务行业准备利用生成式人工智能提供个性化消费体验、成本效益高的运营、更好的合规性、改进的风险管理以及动态预测和报告。</font>

## [生成式人工智能](https://a16z.com/2023/02/07/everyday-ai-consumer/)

<font style="color:rgb(42, 42, 42);">下一代消费者平台：探讨生成式人工智能在从治疗到电子商务等各个领域对消费者市场产生影响的机会。</font>

## [要在医疗保健领域取得真正的差异，人工智能需要像我们一样学习](https://time.com/6274752/ai-health-care/)

<font style="color:rgb(42, 42, 42);">人工智能有望彻底改变我们对预防和治疗疾病的看法。然而，要真正改变从药物研发到护理交付的过程，我们应该投资于创建一个像我们最优秀的医生和药物研发人员今天所做的那样学习的“专家”人工智能的生态系统。</font>

## [新的工业革命：生物与人工智能](https://a16z.com/2023/05/17/the-new-industrial-revolution-bio-x-ai/)

<font style="color:rgb(42, 42, 42);">人类历史上的下一次工业革命将是由人工智能驱动的生物学革命。</font>

## [关于基础模型的机遇和风险](https://arxiv.org/abs/2108.07258)

<font style="color:rgb(42, 42, 42);">斯坦福基础模型概述论文。这篇长篇且有主观观点的论文对基础模型的概念产生了重要影响。</font>

## [人工智能现状报告](https://www.stateof.ai/)

<font style="color:rgb(42, 42, 42);">每年一次的 AI 综述报告，涵盖了人工智能领域的技术突破、行业发展、政治/监管、经济影响、安全性以及未来预测等方面的内容。</font>

## [GPTs 即 GPTs](https://arxiv.org/abs/2303.10130)

<font style="color:rgb(42, 42, 42);">对大型语言模型对劳动力市场影响潜力的早期研究。这篇来自 OpenAI、OpenResearch 和宾夕法尼亚大学的研究人员的论文预测：“大约 80%的美国劳动力可能会有至少 10%的工作任务受到 LLM 引入的影响，而大约 19%的工人可能会看到至少 50%的工作任务受到影响。”</font>

## [深度医学](https://www.amazon.com/Deep-Medicine-Eric-Topol-audiobook/dp/B07PJ21V5N/ref=sr_1_1?hvadid=580688888836&hvdev=c&hvlocphy=9031955&hvnetw=g&hvqmt=e&hvrand=13698160037271563598&hvtargid=kwd-646099228782&hydadcr=15524_13517408&keywords=eric+topol+deep+medicine&qid=1684965845&sr=8-1)

<font style="color:rgb(42, 42, 42);">人工智能如何使医疗恢复人性：埃里克·托普尔博士揭示了人工智能如何潜在地使医生摆脱耗时的任务，从而有助于恢复医患关系的人性化。这个医生与患者之间的联系得到了恢复。</font>

# **<font style="color:rgb(42, 42, 42);">具有里程碑意义的研究成果</font>**

<font style="color:rgb(42, 42, 42);">现在我们看到的许多令人惊叹的人工智能产品，大多是来自大公司和顶尖大学的专家的研究成果。最近，我们还看到了个人和开源社区开展的一些令人印象深刻的工作，他们通过创建自动化代理或将模型移植到更小的硬件上，使流行项目朝着新的方向发展。</font>

<font style="color:rgb(42, 42, 42);">这里是许多这些论文和项目的集合，供那些真正想深入了解生成式人工智能的人使用。（对于研究论文和项目，我们还包括了相关博客文章或网站的链接，以便在可能的情况下更高层次地解释事物。我们还包括了原始出版年份，这样您就可以追踪基础研究的发展。</font>

## **<font style="color:rgb(42, 42, 42);">新的大语言模型</font>**

### [Attention is all you need（2017 年）](https://arxiv.org/abs/1706.03762)

<font style="color:rgb(42, 42, 42);">来自 Google Brain 的原始 Transformer 工作和研究论文，开启了一切。 （</font>[博客文章](https://ai.googleblog.com/2017/08/transformer-novel-neural-network.html)<font style="color:rgb(42, 42, 42);">）</font>

### [BERT：深度双向 Transformer 的预训练语言理解（2018 年）](https://arxiv.org/abs/1810.04805)

<font style="color:rgb(42, 42, 42);">首批公开可用的大语言模型之一，至今仍有许多变体在使用中。（</font>[博客文章](https://ai.googleblog.com/2018/11/open-sourcing-bert-state-of-art-pre.html)<font style="color:rgb(42, 42, 42);">）</font>

### [通过生成式预训练改进语言理解（2018 年）](https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf)

<font style="color:rgb(42, 42, 42);">OpenAI 的第一篇论文，涵盖了 GPT 架构，成为大语言模型领域中主导的发展路径。（</font>[博客文章](https://openai.com/research/language-unsupervised)<font style="color:rgb(42, 42, 42);">）</font>

### [语言模型是几乎零样本学习者（2020 年）](https://arxiv.org/abs/2005.14165)

<font style="color:rgb(42, 42, 42);">OpenAI 的论文，描述了 GPT-3 和现代大语言模型的仅解码器架构。</font>

### [训练语言模型通过人类反馈遵循指令（2022 年）](https://arxiv.org/abs/2203.02155)

<font style="color:rgb(42, 42, 42);">OpenAI 的论文解释了 InstructGPT，该模型利用人类反馈来训练模型，从而更好地遵循提示中的指令。这是使大语言模型对消费者可用的关键因素之一（例如通过 ChatGPT）。 （</font>[博客文章](https://openai.com/research/instruction-following)<font style="color:rgb(42, 42, 42);">）</font>

### [LaMDA：用于对话应用的语言模型（2022 年）](https://arxiv.org/abs/2201.08239)

<font style="color:rgb(42, 42, 42);">谷歌专门为人类和聊天机器人之间在各种话题上进行自由流畅对话而设计的模型。（</font>[博客文章](https://blog.google/technology/ai/lamda/)<font style="color:rgb(42, 42, 42);">）</font>

### [PaLM：通过路径扩展语言建模（2022 年](https://arxiv.org/abs/2204.02311)<font style="color:rgb(42, 42, 42);">）</font>

<font style="color:rgb(42, 42, 42);">谷歌的 PaLM 利用了一种新的系统，在数千个芯片上训练大语言模型，并展示了随着模型规模的扩大而超出预期的改进。 （</font>[博客文章](https://ai.googleblog.com/2022/04/pathways-language-model-palm-scaling-to.html)<font style="color:rgb(42, 42, 42);">）此外，请参阅</font>[PaLM-2 技术报告](https://arxiv.org/abs/2305.10403)<font style="color:rgb(42, 42, 42);">。</font>

### [OPT：开放预训练 Transformer 语言模型（2022 年）](https://arxiv.org/abs/2205.01068)

<font style="color:rgb(42, 42, 42);">OPT 是表现出色的全面开源 LLM 之一。这款拥有 1750 亿参数的模型发布附带了代码，并且是使用公开可用的数据集进行训练的。（</font>[博客文章](https://ai.facebook.com/blog/democratizing-access-to-large-scale-language-models-with-opt-175b/)<font style="color:rgb(42, 42, 42);">）</font>

### [训练计算最优的大型语言模型（2022 年）](https://arxiv.org/abs/2203.15556)

<font style="color:rgb(42, 42, 42);">Chinchilla 论文。它提出了大多数模型是数据受限而不是计算受限的观点，并改变了关于 LLM 扩展的共识。（</font>[博客文章](https://www.deepmind.com/blog/an-empirical-analysis-of-compute-optimal-large-language-model-training)<font style="color:rgb(42, 42, 42);">）</font>

### [GPT-4 技术报告（2023 年](https://arxiv.org/abs/2303.08774)**<font style="color:rgb(42, 42, 42);">）</font>**

<font style="color:rgb(42, 42, 42);">来自 OpenAI 的最新、最伟大的论文，以保密程度而闻名！（</font>[博客文章](https://openai.com/research/gpt-4)<font style="color:rgb(42, 42, 42);">）。</font>[GPT-4 系统卡片](https://cdn.openai.com/papers/gpt-4-system-card.pdf)<font style="color:rgb(42, 42, 42);">为我们了解 OpenAI 如何处理幻觉、隐私、安全和其他问题提供了一些线索。</font>

### [LLaMA：开放且高效的基础语言模型（2023 年）](https://arxiv.org/abs/2302.13971)

<font style="color:rgb(42, 42, 42);">来自 Meta 的模型，（几乎）引发了开源 LLM 革命。与许多最佳闭源模型相媲美，但只对研究人员开放，使用受限的许可证。（</font>[博客文章](https://ai.facebook.com/blog/large-language-model-llama-meta-ai/)<font style="color:rgb(42, 42, 42);">）</font>

### [Alpaca：一种强大且可复制的指令跟随模型（2023 年](https://crfm.stanford.edu/2023/03/13/alpaca.html)<font style="color:rgb(42, 42, 42);">）</font>

<font style="color:rgb(42, 42, 42);">这款来自斯坦福的模型展示了指令调优的威力，尤其是与纯粹的规模相比，对于较小的开源模型而言。</font>

## **<font style="color:rgb(42, 42, 42);">模型优化（fine-tuning, retrieval, attention)</font>**

### [深度强化学习来自人类偏好（2017 年）](https://proceedings.neurips.cc/paper_files/paper/2017/file/d5e2c0adad503c91f91df240d0cd4e49-Paper.pdf)

<font style="color:rgb(42, 42, 42);">研究强化学习在游戏和机器人领域的应用，后来证明是 LLM 的一种出色工具。</font>

### [为知识密集型 NLP 任务增强的检索生成（2020 年）](https://arxiv.org/abs/2005.11401)

<font style="color:rgb(42, 42, 42);">由 Facebook 开发，RAG 是通过信息检索提高 LLM 准确性的两个主要研究方向之一。（</font>[博客文章](https://ai.facebook.com/blog/retrieval-augmented-generation-streamlining-the-creation-of-intelligent-natural-language-processing-models/)<font style="color:rgb(42, 42, 42);">）</font>

### [通过从数万亿标记中检索来改进语言模型（2021 年）](https://arxiv.org/abs/2112.04426)

<font style="color:rgb(42, 42, 42);">RETRO，即“Retrieval Enhanced TRansfOrmers”，是 DeepMind 提出的另一种方法，通过访问其训练数据中未包含的信息来提高 LLM 的准确性。（</font>[博客文章](https://www.deepmind.com/blog/improving-language-models-by-retrieving-from-trillions-of-tokens)<font style="color:rgb(42, 42, 42);">）</font>

### [LoRA：大型语言模型的低秩调整（2021 年）](https://arxiv.org/abs/2106.09685)

<font style="color:rgb(42, 42, 42);">这项来自微软的研究引入了一种在新数据上训练 LLM 的更高效替代方法，现已成为社区微调的标准，特别适用于图像模型。</font>

### [宪法 AI（2022 年）](https://arxiv.org/abs/2212.08073)

<font style="color:rgb(42, 42, 42);">Anthropic 团队介绍了通过 AI 反馈进行强化学习（RLAIF）的概念。主要思想是我们可以在其他 AI 的监督下开发一个无害的 AI 助手。</font>

### [FlashAttention：具有 IO 感知的快速和内存高效的精确注意力（2022 年）](https://arxiv.org/abs/2205.14135)

<font style="color:rgb(42, 42, 42);">这项斯坦福的研究为最先进的模型在理解更长的文本序列（和更高分辨率的图像）方面打开了大门，而无需昂贵的训练时间和成本。（</font>[博客文章](https://ai.stanford.edu/blog/longer-sequences-next-leap-ai/)<font style="color:rgb(42, 42, 42);">）</font>

### [饥饿的河马：走向具有状态空间模型的语言建模（2022 年）](https://arxiv.org/abs/2212.14052)

<font style="color:rgb(42, 42, 42);">再次来自斯坦福，这篇论文描述了语言建模中替代注意力的主要方法之一。这是更好的扩展和训练效率的有希望的途径。（</font>[博客文章](https://hazyresearch.stanford.edu/blog/2023-01-20-h3)<font style="color:rgb(42, 42, 42);">）</font>

## **<font style="color:rgb(42, 42, 42);">图像生成模型</font>**

### [学习可迁移的视觉模型：来自自然语言监督的（2021 年）](https://arxiv.org/abs/2103.00020)

<font style="color:rgb(42, 42, 42);">介绍了一个基础模型 CLIP，将文本描述与图像相连。这是计算机视觉中首次有效的大规模使用基础模型的案例之一。（</font>[博客文章](https://openai.com/research/clip)<font style="color:rgb(42, 42, 42);">）</font>

### [零样本文本到图像生成（2021 年）](https://arxiv.org/abs/2102.12092)

<font style="color:rgb(42, 42, 42);">这篇论文介绍了 DALL-E，一种结合了前面提到的 CLIP 和 GPT-3 的模型，可以根据文本提示自动生成图像。其后继者 DALL-E 2 在 2022 年引爆了基于图像的生成型人工智能热潮。（</font>[博客文章](https://openai.com/research/dall-e)<font style="color:rgb(42, 42, 42);">）</font>

### [使用潜在扩散模型进行高分辨率图像合成（2021 年）](https://arxiv.org/abs/2112.10752)

<font style="color:rgb(42, 42, 42);">这篇论文描述了稳定扩散（在推出和爆炸式开源增长后）。</font>

### [具有深度语言理解的照片般逼真的文本到图像扩散模型（2022 年）](https://arxiv.org/abs/2205.11487)

<font style="color:rgb(42, 42, 42);">Imagen 是谷歌进军 AI 图像生成领域的尝试。截至本文发布日期，该模型仍未公开发布。（</font>[网站](https://imagen.research.google/)<font style="color:rgb(42, 42, 42);">）</font>

### [DreamBooth：用于主题驱动生成的文本到图像扩散模型微调（2022 年）](https://arxiv.org/abs/2208.12242)

<font style="color:rgb(42, 42, 42);">DreamBooth 是谷歌开发的一个系统，用于训练模型识别用户提交的主题并将其应用于提示的上下文中（例如，[用户]在埃菲尔铁塔微笑）。 （</font>[网站](https://dreambooth.github.io/)<font style="color:rgb(42, 42, 42);">）</font>

### [将条件控制添加到文本到图像扩散模型（2023 年）](https://arxiv.org/abs/2302.05543)

<font style="color:rgb(42, 42, 42);">这篇来自斯坦福的论文介绍了 ControlNet，这是一个非常受欢迎的工具，可对潜在扩散模型的图像生成进行细粒度控制。</font>

## **<font style="color:rgb(42, 42, 42);">代理人 Agents</font>**

### [通往自主机器智能的路径（2022 年）](https://openreview.net/pdf?id=BZ5a1r-kVsf)

<font style="color:rgb(42, 42, 42);">Meta AI 负责人、纽约大学教授 Yann LeCun 提出了如何构建真正理解周围世界的自主智能代理的建议。</font>

### [ReAct：在语言模型中协同推理和行动（2022 年）](https://arxiv.org/abs/2210.03629)

<font style="color:rgb(42, 42, 42);">普林斯顿大学和谷歌的一个项目，旨在测试和改进大语言模型的推理和规划能力。（</font>[博客文章](https://ai.googleblog.com/2022/11/react-synergizing-reasoning-and-acting.html)<font style="color:rgb(42, 42, 42);">）</font>

### [生成型代理：人类行为的交互模拟（2023 年）](https://arxiv.org/abs/2304.03442)

<font style="color:rgb(42, 42, 42);">斯坦福大学和谷歌的研究人员利用大语言模型来驱动代理程序，在类似于《模拟人生》的环境中，它们的互动是新型的而不是预设的。</font>

### [Reflexion：具有动态记忆和自反思能力的自主代理（2023 年）](https://arxiv.org/abs/2304.03442)

<font style="color:rgb(42, 42, 42);">东北大学和麻省理工学院的研究人员的工作，通过从错误和过去经验中学习，教导大语言模型更可靠地解决问题。</font>

### [Toolformer：语言模型可以自学使用工具（2023 年）](https://arxiv.org/abs/2303.11366)

<font style="color:rgb(42, 42, 42);">Meta 的这个项目训练大语言模型使用外部工具（在这种情况下是指搜索引擎和计算器等 API）来提高准确性，而无需增加模型大小。</font>

### [Auto-GPT：自主 GPT-4 实验](https://github.com/Significant-Gravitas/Auto-GPT)

<font style="color:rgb(42, 42, 42);">一个开源实验，通过给予 GPT-4 一系列工具（如互联网访问、文件存储等），并选择在解决特定任务时使用哪些工具来扩展 GPT-4 的能力。</font>

### [BabyAGI](https://github.com/yoheinakajima/babyagi)

<font style="color:rgb(42, 42, 42);">这个 Python 脚本利用 GPT-4 和向量数据库（用于存储上下文）来规划和执行一系列解决更广泛目标的任务。</font>

## **<font style="color:rgb(42, 42, 42);">其他数据模式</font>**

### **<font style="color:rgb(42, 42, 42);">编码生成</font>**

#### [针对代码进行大型语言模型的评估（2021 年）](https://arxiv.org/abs/2107.03374)

<font style="color:rgb(42, 42, 42);">这是 OpenAI 针对 GitHub Copilot 产品背后的代码生成模型 Codex 的研究论文。（</font>[博客文章](https://openai.com/blog/openai-codex)<font style="color:rgb(42, 42, 42);">）</font>

#### [使用 AlphaCode 进行竞技级代码生成（2021 年）](https://www.science.org/stoken/author-tokens/ST-905/full)

<font style="color:rgb(42, 42, 42);">DeepMind 的这项研究展示了一个能够比人类程序员编写更好代码的模型。（</font>[博客文章](https://www.deepmind.com/blog/competitive-programming-with-alphacode)<font style="color:rgb(42, 42, 42);">）</font>

#### [CodeGen：用于代码的开放大型语言模型，具备多轮程序综合能力（2022 年）](https://arxiv.org/abs/2203.13474)

<font style="color:rgb(42, 42, 42);">CodeGen 来自 Salesforce 的 AI 研究部门，目前支持 Replit Ghostwriter 产品进行代码生成。（</font>[博客文章](https://blog.salesforceairesearch.com/codegen/)<font style="color:rgb(42, 42, 42);">）</font>

### **<font style="color:rgb(42, 42, 42);">视频生成</font>**

#### [Make-A-Video：无需文本-视频数据的文本到视频生成（2022 年）](https://arxiv.org/abs/2209.14792)

<font style="color:rgb(42, 42, 42);">Meta 的这个模型可以根据文本提示创建短视频，还可以为静态照片输入添加动态效果或创建现有视频的变体。（</font>[博客文章](https://makeavideo.studio/)<font style="color:rgb(42, 42, 42);">）</font>

#### [Imagen Video：使用扩散模型生成高清视频（2022 年）](https://arxiv.org/abs/2210.02303)

<font style="color:rgb(42, 42, 42);">正如其名称所示，这是 Google 的基于图像的 Imagen 模型的一个版本，专门用于根据文本提示生成短视频。（</font>[网站](https://imagen.research.google/video/)<font style="color:rgb(42, 42, 42);">）</font>

### **<font style="color:rgb(42, 42, 42);">生物和医学数据</font>**

#### [预训练图神经网络的策略（2020 年）](https://arxiv.org/pdf/1905.12265.pdf)

<font style="color:rgb(42, 42, 42);">这篇文章为有效的预训练方法奠定了基础，适用于药物发现等领域的应用，如分子属性预测和蛋白质功能预测。（</font>[博客文章](https://snap.stanford.edu/gnn-pretrain/)<font style="color:rgb(42, 42, 42);">）</font>

#### [利用深度学习的潜力改进蛋白质结构预测（2020 年）](https://www.nature.com/articles/s41586-019-1923-7)

<font style="color:rgb(42, 42, 42);">DeepMind 的以蛋白质为中心的 Transformer 模型 AlphaFold 使得从序列预测蛋白质结构成为可能，这是一个真正的突破，对于理解生物过程和开发新的疾病治疗方法已经产生了深远的影响。（</font>[博客文章](https://www.deepmind.com/blog/alphafold-a-solution-to-a-50-year-old-grand-challenge-in-biology)<font style="color:rgb(42, 42, 42);">）（</font>[解释性文章](https://www.blopig.com/blog/2021/07/alphafold-2-is-here-whats-behind-the-structure-prediction-miracle/)<font style="color:rgb(42, 42, 42);">）</font>

#### [大型语言模型编码临床知识（2022 年）](https://arxiv.org/abs/2212.13138)

<font style="color:rgb(42, 42, 42);">Med-PaLM 是一个能够正确回答美国医学执照考试风格问题的大语言模型。该团队随后发布了关于 Med-PaLM2 性能的结果，其得分与“专家”考生相当。其他团队也使用</font>[ChatGPT](https://www.medrxiv.org/content/10.1101/2022.12.19.22283643v2)<font style="color:rgb(42, 42, 42);">和</font>[GPT-4](https://arxiv.org/abs/2303.13375)<font style="color:rgb(42, 42, 42);">进行了类似的实验。（</font>[视频](https://www.youtube.com/watch?v=saWEFDRuNJc)<font style="color:rgb(42, 42, 42);">）</font>

### **<font style="color:rgb(42, 42, 42);">音频生成</font>**

#### [Jukebox：音乐生成的生成模型（2020 年）](https://arxiv.org/abs/2005.00341)

<font style="color:rgb(42, 42, 42);">OpenAI 进入音乐生成领域，使用 Transformer 技术，能够在最小的训练下生成音乐、歌声和歌词。（</font>[博客文章](https://openai.com/research/jukebox)<font style="color:rgb(42, 42, 42);">）</font>

#### [AudioLM：一种基于语言建模的音频生成方法（2022 年）](https://arxiv.org/pdf/2209.03143.pdf)

<font style="color:rgb(42, 42, 42);">AudioLM 是 Google 的一个项目，用于生成多种类型的音频，包括语音和乐器音。（</font>[博客文章](https://ai.googleblog.com/2022/10/audiolm-language-modeling-approach-to.html)<font style="color:rgb(42, 42, 42);">）</font>

#### [MusicLM：从文本生成音乐（2023 年）](https://arxiv.org/abs/2301.11325)

<font style="color:rgb(42, 42, 42);">基于人工智能的音乐生成的当前最先进技术，展示了比以前的尝试更高的质量和连贯性。（</font>[博客文章](https://google-research.github.io/seanet/musiclm/examples/)<font style="color:rgb(42, 42, 42);">）</font>

### **<font style="color:rgb(42, 42, 42);">多维度图片生成</font>**

#### [NeRF: 将场景表示为用于视图合成的神经辐射场（2020 年](https://arxiv.org/abs/2003.08934)**<font style="color:rgb(42, 42, 42);">）</font>**

<font style="color:rgb(42, 42, 42);">由加州大学伯克利分校领导的团队进行的研究，使用 5D 坐标来“合成复杂场景的新视图”。（</font>[网站](https://www.matthewtancik.com/nerf)<font style="color:rgb(42, 42, 42);">）</font>

#### [DreamFusion：使用 2D 扩散进行文本到 3D 转换（2022 年）](https://arxiv.org/pdf/2209.14988.pdf)

<font style="color:rgb(42, 42, 42);">来自 Google 和加州大学伯克利分校的研究人员的工作，在 NeRF 的基础上，从 2D 输入生成 3D 图像。（</font>[网站](https://dreamfusion3d.github.io/)<font style="color:rgb(42, 42, 42);">）</font>
