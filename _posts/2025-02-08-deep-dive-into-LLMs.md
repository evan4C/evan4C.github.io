---
title: deep dive into LLMs
date: 2025-02-08
categories: [AI]
tags: [Andrej Karpathy, LLM, RL]
---

some key takeaways from Andrej's awesome video.

{% include embed/youtube.html id='7xTGNNLPyMI' %}

## Pre-training

### step1: download and preprocess the internet

[fineWeb](https://huggingface.co/spaces/HuggingFaceFW/blogpost-fineweb-v1): a new, large-scale (15-trillion tokens, 44TB disk space) dataset for LLM pre-training.

How to find the raw data: use a public repository of crawled webpages. like the one maintained by the non-profit CommonCrawl

![raw txt to dataset](https://huggingfacefw-blogpost-fineweb-v1.static.hf.space/dist/assets/images/fineweb-recipe.png)

### step2: tokenization

Convert between raw text into sequences ot symbols/tokens

example: ~5000 Unicode characters

- ~= 40.000 bits (2 possible tokens)
- ~= 5000 bytes (256 possible tokens)
- ~= 1300 GPT-4 tokens (100.277 possible tokens)

ä¸€ä¸ªåœ¨çº¿å¯äº¤äº’çš„ tokenizerï¼š[Tiktokenizer](https://tiktokenizer.vercel.app)

### step3: neural network training

[LLM å¯è§†åŒ–](https://bbycroft.net/llm)

ç»™å®šè¾“å…¥å’Œè¾“å‡ºï¼ˆlabelï¼‰ï¼Œå¯¹æ¨¡å‹çš„å‚æ•°è¿›è¡Œè®­ç»ƒ/æ‹Ÿåˆï¼Œè®­ç»ƒå®Œæˆä¹‹åï¼Œä¼šå¾—åˆ°ä¸€ç»„æ»¡æ„çš„æƒé‡ï¼ˆweightsï¼‰ï¼Œç„¶åä¾¿å¯ä»¥è¿›å…¥ä¸‹ä¸€é˜¶æ®µï¼šæ¨ç†ã€‚

### step4: inference

æ ¹æ®ç”¨æˆ·ç»™å®šçš„è¾“å…¥ï¼Œæ¨¡å‹ä¼šåˆ©ç”¨è®­ç»ƒå¾—åˆ°çš„æƒé‡è®¡ç®—å‡ºç›¸åº”çš„è¾“å‡ºï¼Œè¿”å›ç»™ç”¨æˆ·ã€‚

### demo: reproducing OpenAIâ€˜s GPT-2

GPT-2 was published by OpenAl in 2019, in Paper: [Language Models are Unsupervised Multitask Learners](https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf)

GPT-2 is a transformer neural network with:

- 1.6 billion parameters
- maximum **context length** of 1024 tokens
- trained on about 100 billion tokens

My reproduction: [llm.c](https://github.com/karpathy/llm.c/discussions/677), training cost is about 1day/$672.

Why training cost drops so quickly?

1. dataset has gotten much better
2. computers have gotten much faster
3. software has gotten much efficient

![screenshot-training-GPT-2](/assets/img/screenshot-training-GPT-2.png)

æˆªå›¾ä¸­çš„æ¯ä¸€è¡Œä»£è¡¨ä¸€æ¬¡æ¨¡å‹çš„å‚æ•°æ›´æ–°ï¼Œæ¯ä¸€æ¬¡æ›´æ–°ä¼šä» dataset ä¸­æå–**1m token**ä½œä¸ºè¾“å…¥ï¼Œæ—¶é•¿å¤§çº¦ä¸º 7sï¼Œæ€»å…±éœ€å®Œæˆ 32000 æ¬¡æ›´æ–°ã€‚å¯ä»¥çœ‹å‡ºï¼Œéšç€å‚æ•°æ›´æ–°çš„è¿›è¡Œï¼Œæ¨¡å‹çš„æŸå¤±åœ¨é€æ¸é™ä½ã€‚å®Œæˆ 20 æ¬¡æ›´æ–°åï¼Œæ¨¡å‹ä¼šè¿›è¡Œä¸€æ¬¡æ¨ç†ï¼Œç”¨äºæ£€éªŒæ¨¡å‹çš„ç”Ÿæˆæ•ˆæœã€‚

è®­ç»ƒç¡¬ä»¶åˆ†æï¼š

- è®­ç»ƒå¹³å°ï¼š[lambda](https://lambdalabs.com)
- è®­ç»ƒç¡¬ä»¶ï¼š8xH100 node

### base model release

å¤§çš„ç§‘æŠ€å…¬å¸ä¼šå®šæœŸå…¬å¼€ä»–ä»¬è®­ç»ƒå¥½çš„åŸºç¡€æ¨¡å‹ï¼Œå¦‚ä¸‹è¡¨æ‰€ç¤ºï¼š

| åç§°        | å…¬å¸   | å‘å¸ƒæ—¥æœŸ |
| ----------- | ------ | -------- |
| GPT-2 1.6B  | openAI | 2019     |
| llama3 405B | meta   | 2024     |

ä»¥[openAI GPT-2](https://github.com/openai/gpt-2)ä¸ºä¾‹ï¼Œå…¬å¼€çš„å†…å®¹é€šå¸¸åŒ…æ‹¬

1. model.pyï¼šç”¨äºæè¿°æ¨¡å‹ç»“æ„çš„ python ä»£ç 
2. æ¨¡å‹æƒé‡

åŸºç¡€æ¨¡å‹ä¸€èˆ¬ä¸å¸¦æœ‰é—®ç­”åŠŸèƒ½ï¼Œåªä¼šæ ¹æ®è¾“å…¥é¢„æµ‹æ¥ä¸‹æ¥çš„ token æ˜¯ä»€ä¹ˆï¼Œç›¸å½“äºä¸€ä¸ªç½‘ç»œæ–‡æœ¬æ¨¡æ‹Ÿå™¨ï¼ˆinternet document simulatorï¼‰ã€‚ç”±äºå…¶å†…åœ¨çš„æ¦‚ç‡æ¨¡å‹è¾“å‡ºæœºåˆ¶ï¼Œå³ä½¿è¾“å…¥ç›¸åŒçš„æç¤ºè¯ï¼Œæ¯æ¬¡å¾—åˆ°çš„å›å¤éƒ½æ˜¯ä¸ä¸€æ ·çš„ã€‚

å¸¦æœ‰ Instruct åç¼€çš„åŸºç¡€æ¨¡å‹å¯ä»¥ç›´æ¥ä½œä¸ºé—®ç­”åŠ©æ‰‹æ¥ä½¿ç”¨ã€‚

ä½¿ç”¨[Hyperbolic](https://hyperbolic.xyz)å¯¹åŸºç¡€æ¨¡å‹è¿›è¡Œç®€å•æµ‹è¯•ã€‚

## Post-training: SFT

Supervised fine-tuning çš„ç›®çš„æ˜¯åœ¨ base model çš„åŸºç¡€ä¸Šå¾—åˆ°ä¸€ä¸ªæœ‰å®ç”¨ä»·å€¼çš„ assistantï¼Œä½¿ç”¨ conversation exampleï¼ˆé—®ç­”å®ä¾‹ï¼‰è€Œä¸æ˜¯ä»£ç è¿›è¡Œâ€œç¼–ç¨‹â€ã€‚SFT çš„æµç¨‹å’Œ Pre-training å®Œå…¨ä¸€è‡´ï¼Œåªæ˜¯ä¸¤è€…ä½¿ç”¨çš„è®­ç»ƒæ•°æ®é›†ä¸ä¸€æ ·ï¼ŒSFT ä½¿ç”¨æ›´å°çš„é—®ç­”æ•°æ®é›†ï¼Œå› æ­¤è®­ç»ƒæ—¶é—´ä¹Ÿæ›´çŸ­ï¼Œé€šå¸¸åªéœ€è¦å‡ ä¸ªå°æ—¶æˆ–å‡ å¤©å³å¯ã€‚

å¦‚ä½•ä½¿ç”¨ conversation æ•°æ®å¯¹æ¨¡å‹è¿›è¡Œå¾®è°ƒï¼Ÿ
ç±»æ¯” TCP/IP ä¸­çš„æ•°æ®åŒ…ï¼ˆåŒ…å«è¡¨å¤´å’Œæ•°æ®ï¼‰çš„æ¦‚å¿µï¼ŒæŒ‰ç…§ä¸€å®šçš„è§„åˆ™å¯¹ conversation è¿›è¡Œç¼–ç ï¼Œç„¶åå†å°†è¿›è¡Œ tokenizationï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š

åŸå§‹å¯¹è¯ä¸ºï¼š

```
what is 2+2?
2+2=4
what if It was *?
2*2=4, same as 2+2!
```

è¿›è¡Œç¼–ç åçš„å¯¹è¯ä¸ºï¼š

```
<|im_start|>user<|im_sep|>what is 2+2? <|im_end|>
<|im_start|>assistant<|im_sep|>2+2=4<|im_end|>
<|im_start|>user<|im_sep|>what if It was *?<|im_end|>
<|im_start|>assistant<|im_sep|>2*2=4, same as 2+2!<|im_end|>
<|im_start|>assistant<|im_sep|>
```

tokenization ä¹‹åä¸ºï¼š

```
200264, 1428, 200266, 13347, 382, 220, 17, 10, 17, 30, 220, 200265,
200264, 173781, 200266, 17, 10, 17, 28, 19, 200265,
200264, 1428, 200266, 13347, 538, 1225, 673, 425, 30, 200265,
200264, 173781, 200266, 17, 9, 17, 28, 19, 11, 2684, 472, 220, 17, 10, 17, 0, 200265,
200264, 173781, 200266
```

2022 å¹´ openAI å‘å¸ƒäº†å…³äºæ¨¡å‹å¾®è°ƒçš„ç»å…¸è®ºæ–‡ï¼š[Training language models to follow instructions with human feedback](https://arxiv.org/pdf/2203.02155)ã€‚openAI å¹¶æ²¡æœ‰å…¬å¸ƒå…¶ç”¨äºæ¨¡å‹å¾®è°ƒçš„å¯¹è¯æ•°æ®é›†ï¼Œä½†æ˜¯åœ¨ç½‘ä¸Šå¯ä»¥æ‰¾åˆ°ä¸€äº›å¼€æºçš„å¯¹è¯æ•°æ®é›†ï¼Œæ¯”å¦‚[OpenAssistant](https://huggingface.co/datasets/OpenAssistant/oasst2)ã€‚

åœ¨æœ€è¿‘çš„ç ”ç©¶ä¸­ï¼Œæˆ‘ä»¬ä¸å†ä¾èµ–äººå·¥ç”Ÿæˆçš„å¯¹è¯æ•°æ®é›†ï¼Œè€Œæ˜¯åˆ©ç”¨å·²æœ‰çš„ LLM æ¥è‡ªåŠ¨ç”Ÿæˆè¿™äº›å¯¹è¯æ•°æ®é›†ï¼Œç”¨äºæ–°æ¨¡å‹çš„å¾®è°ƒï¼Œä¾‹å¦‚[UltraChat](https://github.com/thunlp/UltraChat)ã€‚

key takeaway

> when you are talking with ChatGPT, you don't get those simultaneous answers from a magic AI, but from a group of highly educated experts hired by openAI.
>
> ChatGPT is a statistical simulation of a human labeler

### Hallucinations

åœ¨[huggingface/inference-playground](https://huggingface.co/spaces/huggingface/inference-playground)ä¸­ï¼Œå¦‚æœä½¿ç”¨ä¸€äº›è¾ƒè€çš„æ¨¡å‹ï¼Œæ¯”å¦‚[falcon-7b-instruct](https://huggingface.co/spaces/huggingface/inference-playground?modelId=tiiuae/falcon-7b-instruct)ï¼Œå½“è¢«é—®åŠä¸€äº›æœæ’°çš„é—®é¢˜æ—¶ï¼Œæˆ‘ä»¬ä¼šå‘ç°æ¨¡å‹åœ¨ç¼–é€ ä¸€äº›å›ç­”ï¼ˆHallucinationï¼‰ï¼Œä¾‹å¦‚ï¼š

> who is Orson Kovacs?
>
> Orson Kovacs is a fictional character in the 1956 science fiction novel "The Space Merchants" by Frederic Brown. The character is a space trader who deals with interplanetary commerce and politics.

#### Mitigation 1: knowledge-based refusal

åœ¨ meta 2024 å¹´å‘è¡¨çš„ä¸€é¡¹ç ”ç©¶ä¸­[The Llama 3 Herd of Models](https://arxiv.org/pdf/2407.21783)ï¼Œä»–ä»¬åœ¨è®­ç»ƒæ•°æ®é›†é‡Œæ·»åŠ äº†ä¸€äº›æ¨¡å‹ä¸çŸ¥é“çš„é—®é¢˜ï¼Œå¹¶å‘Šè¯‰æ¨¡å‹è¿™äº›é—®é¢˜çš„æ­£ç¡®çš„ç­”æ¡ˆæ˜¯ä¸çŸ¥é“ã€‚é€šè¿‡è¿™ä¸€è®­ç»ƒï¼ˆmodel interrogationï¼‰ï¼Œæ¨¡å‹å­¦ä¼šäº†å¦‚ä½•åˆ¤æ–­è‡ªå·±çš„çŸ¥è¯†è¾¹ç•Œï¼Œå¹¶èƒ½å¤Ÿæ­£ç¡®å›ç­”è‡ªå·±ä¸çŸ¥é“çš„é—®é¢˜ï¼Œè€Œä¸æ˜¯ç¼–æ’°ä¸€äº›è™šæ„çš„ç­”æ¡ˆï¼ˆHallucinationï¼‰ï¼Œä¾‹å¦‚ï¼š

> who is Orson Kovacs?
>
> I'm sorry, I don't believe I know.

#### Mitigation 2ï¼šallow the model to search

å¦‚ä½•è®­ç»ƒæ¨¡å‹æŒæ¡è”ç½‘æœç´¢èƒ½åŠ›ï¼Œå’Œä¸Šé¢çš„é€»è¾‘ç±»ä¼¼ï¼Œæƒ³è¦æ¨¡å‹æŒæ¡æŸç§èƒ½åŠ›ï¼Œå°±é€šè¿‡ä¾‹å­ï¼ˆexampleï¼‰è®©å®ƒå»å­¦ä¹ è¿™ç§èƒ½åŠ›ã€‚è¿™å…¶å®æ˜¯ä¸€ç§å’Œä¼ ç»Ÿè½¯ä»¶å¼€å‘å®Œå…¨ä¸åŒçš„æ€è€ƒé€»è¾‘ï¼Œåœ¨ä¼ ç»Ÿçš„è½¯ä»¶å¼€å‘æµç¨‹ä¸­ï¼Œéœ€è¦æ–°åœºæ™¯æ–°éœ€æ±‚æ—¶ï¼Œéœ€è¦ç»éªŒä¸°å¯Œçš„ç¨‹åºå‘˜å»è®¾è®¡ç®—æ³•å’Œé€»è¾‘æ¥è§£å†³éœ€æ±‚ã€‚ä½†æ˜¯å¯¹äº LLM è€Œè¨€ï¼Œæˆ‘ä»¬ä¸éœ€è¦å…³æ³¨æ¨¡å‹æ˜¯å¦‚ä½•è§£å†³é—®é¢˜çš„ï¼Œè€Œåªéœ€è¦å‡†å¤‡è¶³å¤Ÿå¤šçš„æ¡ˆä¾‹ï¼Œå‘Šè¯‰å®ƒæˆ‘ä»¬æƒ³è¦æ€æ ·çš„ç»“æœï¼ŒLLM ä¼šè‡ªå·±å­¦ä¼šè§£å†³é—®é¢˜çš„é€»è¾‘ã€‚

å› æ­¤ï¼Œæˆ‘ä»¬éœ€è¦æ„å»ºä¸€ä¸ªè”ç½‘æœç´¢çš„é—®ç­”æ•°æ®é›†ï¼Œä¾‹å¦‚ï¼š

> Human: "Who is Orson Kovacs?"
>
> Assistant: "<SEARCH_START>Who is Orson Kovacs?<SEARCH_END>
> [...]
> Orson Kovacs appears to be ..."

- Knowledge in the parameters == **Vague recollection** (e.g. of something you read 1 month ago)
- Knowledge in the tokens of the context window == **Working memory**

ç”±äº llm å¹¶ä¸çŸ¥é“è‡ªå·±æ˜¯é€šè¿‡æ€æ ·çš„æ–¹å¼è®­ç»ƒå‡ºæ¥çš„ï¼Œæ‰€ä»¥è¯¢é—® llm è¿™ç±»é—®é¢˜æ˜¯æ²¡æœ‰ä»»ä½•æ„ä¹‰çš„ã€‚å³ä½¿ llm å›å¤è‡ªå·±æ˜¯ ChatGPTï¼Œå¹¶ä¸æ„å‘³ç€ llm åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­é‡‡ç”¨äº† openAI çš„æ•°æ®ï¼Œå› ä¸º openAI çš„ chatGPT åœ¨ llm é¢†åŸŸå½±å“åŠ›éå¸¸å¤§ï¼Œå› æ­¤å½“æ¨¡å‹è¢«é—®åŠ"ä½ æ˜¯è°"æ—¶ï¼Œä¼šå¾ˆè‡ªç„¶çš„ç»™å‡ºç»Ÿè®¡å­¦æ„ä¹‰ä¸Šæ¦‚ç‡æœ€é«˜çš„ç­”æ¡ˆï¼š"chatGPT made by openAI"

å½“ç„¶å¼€å‘è€…å¯ä»¥é‡‡å–ä¸€äº›æ‰‹æ®µå›é¿è¿™ç§æƒ…å†µï¼Œä¾‹å¦‚åœ¨ allenai å›¢é˜Ÿæ¨å‡ºçš„å¼€æºæ¨¡å‹[OLMo2](https://huggingface.co/datasets/allenai/tulu-3-sft-olmo-2-mixture)ä¸­ï¼Œå¼€å‘å›¢é˜Ÿåœ¨å¾®è°ƒçš„è¿‡ç¨‹ä¸­æ’å…¥ä¸€ä¸ªç¡¬ç¼–ç æ•°æ®é›†ï¼ˆOLMo 2 Hardcoded (CC-BY-4.0), 240 promptsï¼‰ï¼Œæ˜¾å¼å‘Šè¯‰æ¨¡å‹ï¼š"I'm OLMo, an open language model developed by AI2"ã€‚

å¦ä¸€ç§å¸¸è§çš„æ‰‹æ®µæ˜¯é€šè¿‡åœ¨æœ€å¼€å§‹æ’å…¥ system message çš„æ–¹å¼ï¼Œåœ¨ä»»ä½•å¯¹è¯å¼€å§‹ä¹‹å‰æé†’æ¨¡å‹ä¸€äº›å…³é”®ä¿¡æ¯ã€‚

### Other limitations of llm

#### Models need tokens to think

è€ƒè™‘ä¸‹é¢çš„ä¸¤ä¸ªé—®ç­”ï¼Œä½ è®¤ä¸ºå“ªä¸ªå›ç­”èƒ½å¤Ÿæ›´å¥½çš„è®­ç»ƒæ¨¡å‹çš„é€»è¾‘æ€ç»´ï¼Ÿ

> Human: "Emily buys 3 apples and 2 oranges. Each orange costs $2. The total cost of all the fruit is $13.
> What is the cost of apples?"
>
> Assistant1: "The answer is $3. This is because 2 oranges at $2 are $4 total.
> So the 3 apples cost $9, and therefore each apple is 9/3 = $3".
>
> Assistant2: "The total cost of the oranges is $4.
> 13 - 4 = 9, the cost of the 3 apples is $9.
> 9/3 = 3, so each apple costs $3.
> The answer is $3".

æ­£ç¡®çš„ç­”æ¡ˆæ˜¯ç¬¬ 2 ä¸ªå›ç­”ï¼Œæˆ‘ä»¬éœ€è¦ç‰¢è®° llm æ¨¡å‹çš„æœ¬è´¨æ˜¯é¢„æµ‹ä¸‹ä¸€ä¸ª tokenï¼Œå› æ­¤ llm éœ€è¦ä»å·¦åˆ°å³è¯»å– token å¹¶è¿›è¡Œæ¨ç†ï¼ˆé¢„æµ‹ï¼‰ã€‚åœ¨ç¬¬ 1 ä¸ªå›ç­”ä¸­ï¼Œllm å®é™…ä¸Šéœ€è¦å…ˆéšæœºçŒœå‡ºç­”æ¡ˆæ˜¯ 3ï¼Œç„¶ååœ¨è®ºè¯ç­”æ¡ˆä¸ºä»€ä¹ˆæ˜¯ 3ã€‚è€Œç¬¬ 2 ä¸ªå›ç­”ä¸­ï¼Œæ¨¡å‹æ˜¯æŒ‰ç…§æ•°å­¦è¿ç®—ä¸€æ­¥ä¸€æ­¥æ¨ç†å‡ºæ­£ç¡®ç­”æ¡ˆæ˜¯ 3ã€‚

#### Models can't count and do spelling check

åŸºäºå’Œä¸Šé¢çš„ç›¸åŒçš„åŸå› ï¼Œllm æ— æ³•è¿›è¡Œæœ‰æ•ˆçš„è®¡æ•°å’Œæ‹¼å†™æ£€æŸ¥æ“ä½œï¼Œå› ä¸º llm çš„è¾“å…¥ä¼šè¢«é¦–å…ˆè½¬æ¢æˆ tokenï¼Œåœ¨è½¬æ¢æˆ token çš„è¿‡ç¨‹ä¸­ä¼šä¸¢å¤±ä¸€éƒ¨åˆ†åŸå§‹ä¿¡æ¯ï¼Œä¾‹å¦‚å¯¹äºå•è¯ Ubiquitousï¼Œæ¨¡å‹å®é™…çœ‹åˆ°çš„æ˜¯ 3 ä¸ª tokenï¼ˆ50668, 5118, 50855ï¼‰ï¼Œåˆ†åˆ«å¯¹åº”è¿™ä¸ªå•è¯çš„ 3 ä¸ªè¯æ ¹ï¼ŒUbï¼Œiquï¼Œitousã€‚

ç›®å‰ç”±äºè®¡ç®—æ•ˆç‡ç­‰å› ç´ ï¼Œé‡‡ç”¨ token æ¥è¿›è¡Œåˆ†è¯ä»ç„¶æ˜¯æœ€ä¸»æµçš„åšæ³•ï¼Œä¹Ÿè®¸å°†æ¥ä¼šå‡ºç°å­—æ¯çº§æˆ–å­—èŠ‚çº§çš„æ¨¡å‹ï¼Ÿ

åŒæ—¶å¯¹äºè¿™ç±»é—®é¢˜ï¼Œæ¨¡å‹å¾€å¾€éœ€è¦åœ¨ä¸€æ¬¡é¢„æµ‹ï¼ˆforward propagationï¼‰ä¸­ç²¾ç¡®ç»™å‡ºç­”æ¡ˆï¼Œè¿™ä¹Ÿä¼šå‡ä½æ¨¡å‹çš„å‡†ç¡®æ€§ã€‚

#### Mitigation: use code

åœ¨å®é™…è¿‡ç¨‹ä¸­ï¼Œä¸ºäº†é¿å…æ¨¡å‹å¾—å‡ºé”™è¯¯çš„ç­”æ¡ˆï¼Œä¸€ä¸ªå¸¸ç”¨çš„æŠ€å·§æ˜¯å‘Šè¯‰ llm ä½¿ç”¨å·¥å…·ï¼Œå³**use code**ã€‚ä½¿ç”¨ä»£ç è®¡ç®—å‡ºçš„ç»“æœå¾€å¾€æ¯”æ¨¡å‹é€šè¿‡ä¸€æ¬¡é¢„æµ‹æˆ–"å¿ƒç®—"å¾—åˆ°çš„ç»“æœæ›´å¯é ã€‚

## Post-training: Reinforcement Learning

å¼ºåŒ–å­¦ä¹ å®é™…ä¸Šä¹Ÿæ˜¯åœ¨æ¨¡æ‹Ÿäººå­¦ä¹ çš„è¿‡ç¨‹ã€‚ä¾‹å¦‚å½“æˆ‘ä»¬åœ¨å­¦æ ¡å­¦ä¹ æ–°çš„çŸ¥è¯†æ—¶ï¼Œæˆ‘ä»¬é¦–å…ˆä¼šé˜…è¯»è¯¾æœ¬ä¸Šçš„å†…å®¹ï¼ˆPre-trainingï¼‰ï¼Œç„¶åè€å¸ˆä¼šç»™æˆ‘ä»¬æ¼”ç¤ºä¸€äº›ä¹ é¢˜ï¼Œå¹¶è¯¦ç»†è®²è§£è¿™äº›é¢˜ç›®çš„è§£é¢˜æ€è·¯ï¼ˆSFTï¼‰ï¼Œæœ€åæˆ‘ä»¬ä¼šå°è¯•è‡ªå·±ç‹¬ç«‹è§£é¢˜ï¼Œç„¶åå¯¹ç…§ç­”æ¡ˆæ£€æŸ¥æˆ‘ä»¬çš„è§£é¢˜æ€è·¯æ˜¯å¦æ­£ç¡®ï¼Œé€šè¿‡å¤§é‡çš„ä¹ é¢˜ç»ƒä¹ ï¼Œæˆ‘ä»¬å­¦ä¼šäº†æ–°çš„çŸ¥è¯†ï¼ˆreinforcement learningï¼‰ã€‚

RL çš„å®é™…æµç¨‹ï¼š

1. æ¨¡å‹å¾—åˆ°ä¸€ä¸ªé—®é¢˜ï¼ˆpromptï¼‰å’Œæœ€ç»ˆç­”æ¡ˆ
2. æ¨¡å‹æ ¹æ®é—®é¢˜ç»™å‡ºå¤§é‡ä¸åŒçš„ solutions
3. å¯¹æ¯”ä¸åŒ solutions å¾—åˆ°çš„ç­”æ¡ˆå’Œæœ€ç»ˆç­”æ¡ˆï¼Œé€‰å‡ºå…¶ä¸­è¾ƒå¥½çš„ solution (optimization)
4. ä½¿ç”¨é€‰å‡ºçš„ solution å¯¹æ¨¡å‹è¿›è¡Œè®­ç»ƒ

### DeepSeek R1: Reasoning model

é¢„è®­ç»ƒå’Œç›‘ç£å¾®è°ƒç›®å‰å·²ç»è¢«å…¬è®¤ä¸º llm è®­ç»ƒå¿…ä¸å¯å°‘çš„ç¯èŠ‚ï¼Œä½†æ˜¯å¯¹äºå¼ºåŒ–å­¦ä¹ ï¼Œè™½ç„¶ä¸€äº›å¤§çš„ç§‘æŠ€å…¬å¸åœ¨å†…éƒ¨å·²ç»å¼€å§‹æœ‰ä¸€äº›å°è¯•ï¼Œä½†æ˜¯è¿™äº›å…¬å¸å¹¶æ²¡æœ‰å°†å…¶ç ”ç©¶æˆæœå…¬å¼€å‘è¡¨ï¼Œå› æ­¤å¤§å®¶å¯¹å¼ºåŒ–å­¦ä¹ çš„è®­ç»ƒç»†èŠ‚å¹¶ä¸æ˜¯å¾ˆæ¸…æ¥šã€‚è¿™ä¹Ÿæ˜¯ä¸ºä»€ä¹ˆå½“ DeepSeek ç¬¬ä¸€æ¬¡åœ¨ç½‘ç»œå…¬å¼€å…¶ç›¸å…³ç ”ç©¶æˆæœ[DeepSeek R1](https://arxiv.org/pdf/2501.12948)åï¼Œèƒ½å¤Ÿå¼•èµ·å¦‚æ­¤å·¨å¤§çš„å…³æ³¨åº¦çš„åŸå› ã€‚

> Wait, wait. Wait. Thatâ€™s an aha moment I can flag here.

ä¸Šé¢çš„ç»å…¸è‡ªç™½å‡ºè‡ª DeepSeek-R1-Zero åœ¨è§£é¢˜ä¸­çš„æ€è€ƒè¿‡ç¨‹ï¼Œé€šè¿‡å¼ºåŒ–å­¦ä¹ ï¼Œæ¨¡å‹å¯ä»¥çœŸæ­£æŒæ¡æˆ–æ¶Œç°å‡ºæ€è€ƒçš„èƒ½åŠ›ï¼ˆCoTï¼‰ï¼Œè¿™ç§åœ¨ç»™å‡ºå…·ä½“ç­”å¤ä¹‹å‰çš„æ€è€ƒè¿‡ç¨‹æ— æ³•é€šè¿‡ SFT å¼ºåŠ ç»™æ¨¡å‹ï¼Œä¹Ÿæ— æ³•é€šè¿‡å­¦ä¹ äººç±»çš„æ ‡æ³¨æ•°æ®æ¥æŒæ¡ï¼Œè€Œå¿…é¡»ç”±æ¨¡å‹è‡ªå·±é€šè¿‡å¤§é‡çš„ç»ƒä¹ æ¥è‡ªå‘ç”Ÿæˆã€‚

ä¸€äº›å¸¸ç”¨çš„ Reasoning modelï¼šD[eepSeek-R1-Zero](https://chat.deepseek.com), [chatGPT o1](https://chatgpt.com), [Gemini 2.0 Flash Thinking Experimental](https://aistudio.google.com/prompts/new_chat)

å¦ä¸€ä¸ªç»å…¸çš„å¼ºåŒ–å­¦ä¹ ä¾‹å­æ˜¯ 2017 å¹´çš„[AlphaGO](https://ics.uci.edu/~dechter/courses/ics-295/winter-2018/papers/nature-go.pdf)ï¼Œåœ¨å…¶ç ”ç©¶è®ºæ–‡ä¸­ï¼Œç ”ç©¶è€…å‘ç°ï¼Œå¦‚æœåªé‡‡ç”¨ Supervised learningï¼Œå³è®© AI å­¦ä¹ å’Œæ¨¡æ‹Ÿäººç±»é¡¶çº§é€‰æ‰‹æ˜¯å¦‚ä½•ä¸‹æ£‹çš„ï¼Œå³ä½¿ç»è¿‡é•¿æ—¶é—´çš„è®­ç»ƒï¼ŒAI çš„æ°´å¹³ä¹Ÿåªèƒ½æ¥è¿‘äºäººç±»é¡¶çº§é€‰æ‰‹çš„æ°´å¹³ï¼Œè€Œæ— æ³•è¶…è¶Šäººç±»é¡¶çº§é€‰æ‰‹ã€‚ä½†æ˜¯åˆ©ç”¨ Reinforcement learningï¼ŒAI çš„ä¸‹æ£‹æ°´å¹³ä¾¿å¯ä»¥è¶…è¿‡äººç±»é¡¶çº§é€‰æ‰‹ã€‚
![AlphaGO-Zero](/assets/img/AlphaGO-Zero-training-results.png)

### RL-HF: RL in un-verifiable domains

å¯¹äºä¸€äº›å¼€æ”¾æ€§çš„é—®é¢˜ï¼Œæˆ‘ä»¬å¾ˆéš¾å¾—åˆ°ä¸€ä¸ªæ ‡å‡†ç­”æ¡ˆæˆ–è€…æœ‰ä¸€ä¸ªæ˜ç¡®çš„æ ‡å‡†åˆ¤æ–­ç­”æ¡ˆçš„å¥½åï¼Œä¾‹å¦‚ä¸‹é¢çš„é—®é¢˜ï¼š

> write a joke about pelicans.

åœ¨è¿™ç§åœºåˆä¸‹ï¼Œå¼ºåŒ–å­¦ä¹ å¾ˆéš¾å‘æŒ¥ä½œç”¨ï¼Œé’ˆå¯¹è¿™ä¸€é—®é¢˜ï¼ŒopenAI åœ¨å…¶ 2020 å¹´å‘è¡¨çš„è®ºæ–‡[Fine-Tuning Language Models from Human Preferences](https://arxiv.org/pdf/1909.08593)ä¸­æå‡ºäº†ä¸€ç§è§£å†³æ–¹æ¡ˆï¼šReinforcement learning from Human Feedbackï¼Œå…¶æ ¸å¿ƒæ€æƒ³å¦‚ä¸‹ï¼š

Naive approach:

Run RL as usual, of 1000 updates of 1000 prompts of 1000 roll-outs. (cost. 1,000,000,000 scores from humans!)

RL-HF approach:

- STEP 1: Take 1000 prompts, get 5 roll-outs, order them from best to worst. (cost: 5000 scores from humans)
- STEP 2: Train a neural net simulator of human preferences ("reward model")
- STEP 3: Run RL as usual, but using the simulator instead of actual humans

#### RL-HF çš„ä¼˜ç‚¹

1. å…è®¸æˆ‘ä»¬åœ¨ä»»æ„é¢†åŸŸï¼ˆun-verifiable domainsï¼‰æ‰§è¡Œå¼ºåŒ–å­¦ä¹ 
2. é€šè¿‡"discriminator - generator gap"æ”¹å–„æ¨¡å‹çš„æ€§èƒ½ã€‚å› ä¸ºåœ¨å¤§å¤šæ•°æƒ…å†µä¸‹ discriminate æ¯” generate æ›´å®¹æ˜“ï¼Œä¾‹å¦‚å¯¹äº"Write a poem about winter"è¿™ç±»é—®é¢˜ï¼Œè®© human labeler å†™å‡ºä¸€é¦–å®Œç¾ç¬¦åˆé—®é¢˜æè¿°çš„è¯—æ¯”è®©å…¶åˆ¤æ–­æ¨¡å‹ç”Ÿæˆçš„ 5 é¦–è¯—ä¸­å“ªä¸ªæœ€å¥½è¦éš¾å¾—å¤šã€‚

#### RL-HF çš„ç¼ºç‚¹

RL-HF åªæ˜¯ a lossy simulation of humansï¼Œå®ƒå¹¶ä¸èƒ½å®Œç¾åæ˜ äººç±»çš„è§‚ç‚¹ï¼Œä¹Ÿæ²¡æœ‰ä¸€ä¸ªçœŸæ­£çš„å¤§è„‘æ¥å¤„ç†æ‰€æœ‰å¯èƒ½çš„æƒ…å†µï¼Œè¿™ä¼šäº§ç”Ÿå¾ˆå¤šè¯¯å¯¼æ€§çš„ç»“æœã€‚

æ­¤å¤–ï¼Œéšç€è®­ç»ƒæ¬¡æ•°çš„å¢åŠ ï¼Œæ¨¡å‹ç»å¸¸ä¼šå‘ç° adversarial examples æ¥æ¬ºéª— reward modelï¼Œä¾‹å¦‚åœ¨è®­ç»ƒçš„å‰ 1000 æ¬¡æ›´æ–°ï¼Œæ¨¡å‹ç”Ÿæˆçš„ç¬‘è¯å¯èƒ½åœ¨é€æ¸å˜å¥½ï¼Œä½†æ˜¯è¶…è¿‡ 1000 æ¬¡ä¹‹åï¼Œæ¨¡å‹å¯èƒ½ä¼šç”Ÿæˆå®Œå…¨æ— æ„ä¹‰çš„ç»“æœä½†æ˜¯ä» reward model æ‹¿åˆ°éå¸¸é«˜çš„è¯„åˆ†ï¼Œæ¯”å¦‚"the the the the the the the the"ï¼Œè¿™ç§ adversarial examples é€šå¸¸æ˜¯æ— ç©·æ— å°½çš„ï¼Œæ— æ³•é€šè¿‡äººä¸ºçš„è®¾ç½®è¾ƒä½çš„åˆ†æ•°æ¥è¿›è¡Œæ”¹è¿›ã€‚

å¯¹äº verifiable domains çš„é—®é¢˜åˆ™ä¸ä¼šæœ‰è¿™ç§é—®é¢˜ï¼Œå› ä¸ºæ­£ç¡®ç­”æ¡ˆé€šå¸¸æ˜¯æ˜ç¡®ä¸”æ¸…æ™°çš„ï¼Œæ¯”å¦‚æ•°å­¦å…¬å¼çš„ç»“æœï¼Œæ¨¡å‹æ— æ³•æ‰¾åˆ°ä¸€ç§æŠ•æœºå–å·§çš„æ–¹æ³•æ¥å¾—åˆ°æ­£ç¡®ç­”æ¡ˆï¼Œå› æ­¤åœ¨ verifiable domainsï¼Œå¼ºåŒ–å­¦ä¹ çš„è®­ç»ƒæ¬¡æ•°å¯ä»¥æ— é™åˆ¶å¢åŠ ï¼Œè€Œå¹¶ä¸ä¼šå¯¹æ¨¡å‹çš„å®é™…ç²¾åº¦é€ æˆè´Ÿé¢å½±å“ã€‚

å› æ­¤ RL-HF å¹¶ä¸èƒ½è¢«çœ‹ä½œ"çœŸæ­£çš„"å¼ºåŒ–å­¦ä¹ ï¼Œå› ä¸ºå®ƒçš„ reward function æ˜¯å¯ä»¥è¢«æ¬ºéª—çš„ï¼ˆgamedï¼‰ï¼Œå¹¶ä¸”æ¨¡å‹æ— æ³•åœ¨å¦‚æ­¤çŸ­çš„è®­ç»ƒæ—¶é—´å†…äº§ç”ŸçœŸæ­£çš„æ€è€ƒï¼ˆDeepSeek-R1-Zero çš„"Aha moment"ï¼‰ï¼ŒRL-HF åº”è¯¥è¢«è§†ä¸ºå¦ä¸€ç§ fine-tuningï¼Œå¯ä»¥ç•¥å¾®æ”¹è¿›æ¨¡å‹çš„æ•ˆæœï¼Œä½†æ˜¯æ— æ³•è®©å…¶äº§ç”Ÿæœ¬è´¨æ€§çš„è¿›æ­¥ã€‚

## æ€»ç»“å’Œæœªæ¥å±•æœ›

llm å°±åƒä¸€å—ç‘å£«å¥¶é…ª ğŸ§€ï¼Œå®ƒåœ¨å¤§å¤šæ•°æƒ…å†µä¸‹å“å°èµ·æ¥å¾ˆç¾å‘³ï¼ˆgive good resultsï¼‰ï¼Œä½†æ˜¯ä¹Ÿæœ‰å¾ˆå¤šéšæœºåˆ†å¸ƒçš„æ´æ´ï¼ˆgive dumb resultsï¼‰ï¼Œæœ€å¥½çš„æ–¹æ³•æ˜¯æŠŠå®ƒå½“æˆä¸€ä¸ªå·¥å…·æ¥ä½¿ç”¨ã€‚

### æœªæ¥å‘å±•æ–¹å‘

- å¤šæ¨¡æ€ multi-modalï¼Œå°† llm æ‰©å±•åˆ°éŸ³é¢‘ï¼Œå›¾åƒï¼Œè§†é¢‘é¢†åŸŸï¼Œå’Œ llm å¹¶æ²¡æœ‰æœ¬è´¨æ€§çš„åŒºåˆ«ï¼Œåªæ˜¯å°†å…¶è®­ç»ƒçš„ token èŒƒå›´è¿›è¡Œäº†æ‰©å±•ã€‚
- tasks -> agentsï¼Œagents å¯ä»¥æ‰§è¡Œæ—¶é—´è·¨åº¦æ›´é•¿ï¼Œå†…å®¹æ›´å¤æ‚çš„ä»»åŠ¡
- pervasive, invisibleï¼Œllm å°†è¢«é›†æˆå’Œæ•´åˆåˆ°è¶Šæ¥è¶Šå¤šçš„é¢†åŸŸ
- test-time trainingï¼Œllm åœ¨å®Œæˆé¢„è®­ç»ƒä¹‹åï¼Œå…¶æƒé‡ä¼šè¢«å›ºå®šï¼Œåœ¨åç»­ä½¿ç”¨è¿‡ç¨‹ä¸­æ˜¯æ— æ³•æ›´æ”¹çš„ï¼Œè¿™ä¸€ç‚¹å’Œäººç±»æœ‰å¾ˆå¤§çš„ä¸åŒã€‚äººçš„å¤§è„‘æ¯æ—¶æ¯åˆ»éƒ½åœ¨å­¦ä¹ ï¼Œå…¶å†…éƒ¨çš„ç¥ç»å…ƒä¸æ˜¯å›ºå®šä¸å˜çš„ï¼Œè€Œæ˜¯æ—¶æ—¶åˆ»åˆ»éƒ½åœ¨æ›´æ–°ï¼Œæœªæ¥çš„ llm å¯èƒ½ä¹Ÿä¼šå…·æœ‰è¿™ç§ç‰¹æ€§ã€‚

### å¦‚ä½•è·Ÿè¸ªæœ€æ–°çš„è¿›å±•å’Œåœ¨æ—¥å¸¸ä¸­ä½¿ç”¨è¿™äº› llm

1. [llm leader board](https://lmarena.ai/?leaderboard): å®æ—¶æŸ¥çœ‹å½“å‰æ€§èƒ½æœ€å¥½çš„ llmï¼Œç‚¹å‡»é“¾æ¥å¯ä»¥è·³è½¬åˆ°æ¨¡å‹çš„ä½¿ç”¨ç•Œé¢
2. [ai news letter](https://buttondown.com/ainews): æ¯å¤©è·å–æœ€æ–°çš„ AI è¿›å±•
3. X/Twitter: follow ä¸€äº›çŸ¥åç ”ç©¶è€…
4. [together.ai](https://api.together.ai/playground/chat/deepseek-ai/DeepSeek-R1): æä¾›å„ç§å¼€æºæ¨¡å‹çš„ assistant ç‰ˆæœ¬
5. [hyperbolic](https://app.hyperbolic.xyz/models/deepseek-r1-zero): æä¾›å„ç§å¼€æºæ¨¡å‹çš„åŸºç¡€æ¨¡å‹
6. ä½¿ç”¨[LMStudio](https://lmstudio.ai)åœ¨æœ¬åœ°è¿è¡Œ distilled å¤§æ¨¡å‹
